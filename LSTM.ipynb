{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "yrU0iWdalVGx",
      "metadata": {
        "id": "yrU0iWdalVGx"
      },
      "source": [
        "# Import all the required libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4189cf86",
      "metadata": {
        "id": "4189cf86",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import torch\n",
        "from torch.nn import Module, LSTM, Linear\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dsMIlQ8DnVOJ",
      "metadata": {
        "id": "dsMIlQ8DnVOJ"
      },
      "source": [
        "# ML Model (LSTM)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "01a7fb77",
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate=0.2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (c0, h0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2840da90",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(x,y, batch_size = 64, hidden_size = 32, num_layers = 2, dropout_rate = 0.2, learning_rate = 0.001,input_size = 1, part_train = 0.7, part_valid = 0.2): \n",
        "    epoch = 150\n",
        "\n",
        "    use_cuda = True\n",
        "\n",
        "    # Data loading\n",
        "    train_X = x[:int(part_train * len(x))]\n",
        "    train_Y = y[:int(part_train * len(y))]\n",
        "    valid_X = x[int(part_train * len(x)): int(part_train * len(x)) + int(part_valid * len(x))]\n",
        "    valid_Y = y[int(part_train * len(y)): int(part_train * len(y)) + int(part_valid * len(y))]\n",
        "\n",
        "    train_X, train_Y = torch.from_numpy(train_X).float().unsqueeze(-1), torch.from_numpy(train_Y).float()\n",
        "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=batch_size, shuffle=True)    \n",
        "\n",
        "    valid_X, valid_Y = torch.from_numpy(valid_X).float().unsqueeze(-1), torch.from_numpy(valid_Y).float()\n",
        "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=batch_size)\n",
        "\n",
        "    # Training parameters\n",
        "    device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\") \n",
        "    model = LSTMModel(input_size, hidden_size, num_layers, dropout_rate=dropout_rate).to(device)      \n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    valid_loss_min = float(\"inf\")\n",
        "    bad_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    train_loss_array_per_epoch = []\n",
        "    valid_loss_array_per_epoch = []\n",
        "\n",
        "    # Training epochs\n",
        "    for epoch in tqdm(range(epoch)):\n",
        "        model.train(True)                  \n",
        "        train_loss_array = []\n",
        "        hidden_train = None\n",
        "\n",
        "        #Train phase\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            batch_x, batch_y = batch[0].to(device), batch[1].to(device)\n",
        "            pred_y = model(batch_x) \n",
        "\n",
        "            optimizer.zero_grad()               \n",
        "            loss = criterion(pred_y, batch_y)  \n",
        "            loss.backward()                     \n",
        "            optimizer.step()     \n",
        "\n",
        "            train_loss_array.append(loss.item())\n",
        "            global_step += 1\n",
        "                \n",
        "        #Eval phase\n",
        "        model.eval()                    \n",
        "        valid_loss_array = []\n",
        "\n",
        "        for i, batch in enumerate(valid_loader):\n",
        "            batch_v_x , batch_v_y= batch[0].to(device), batch[1].to(device)\n",
        "            pred_Y= model(batch_v_x)\n",
        "\n",
        "            loss = criterion(pred_Y, batch_v_y)  \n",
        "\n",
        "            valid_loss_array.append(loss.item())\n",
        "\n",
        "        train_loss_cur = np.mean(train_loss_array)\n",
        "        valid_loss_cur = np.mean(valid_loss_array)\n",
        "        train_loss_array_per_epoch.append(train_loss_cur)\n",
        "        valid_loss_array_per_epoch.append(valid_loss_cur)\n",
        "        \n",
        "\n",
        "        # Save if better\n",
        "        if valid_loss_cur < valid_loss_min:\n",
        "            valid_loss_min = valid_loss_cur\n",
        "            bad_epoch = 0\n",
        "            torch.save(model.state_dict(),\"LSTMModel.pth\")\n",
        "        # else:\n",
        "        #     bad_epoch += 1\n",
        "        #     if bad_epoch > 15:\n",
        "        #         break\n",
        "    plt.plot(train_loss_array_per_epoch[1:], label='Training loss')\n",
        "    # #plt.plot(valid_loss_array_per_epoch[1:], label='Validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "299200c3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Window</th>\n",
              "      <th>layers</th>\n",
              "      <th>hidden</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>mse</th>\n",
              "      <th>epochs</th>\n",
              "      <th>input_size</th>\n",
              "      <th>output_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.013232</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.015424</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.017622</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.018151</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.019764</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.645080</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.765182</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.881225</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.998019</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0500</td>\n",
              "      <td>6.861587</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Window  layers  hidden  batch_size  dropout  learning_rate  \\\n",
              "24  LSTM      15       1      64          16      0.0         0.0050   \n",
              "30  LSTM      15       1      64          16      0.0         0.0010   \n",
              "38  LSTM      15       1      64          16      0.0         0.0050   \n",
              "20  LSTM      15       1      64          16      0.0         0.0050   \n",
              "29  LSTM      15       1      64          16      0.0         0.0005   \n",
              "..   ...     ...     ...     ...         ...      ...            ...   \n",
              "63  LSTM      50       3      64          16      0.2         0.0050   \n",
              "48  LSTM      15       4      32          16      0.2         0.0050   \n",
              "49  LSTM      15       3       8          16      0.2         0.0050   \n",
              "64  LSTM      50       3      64          16      0.2         0.0100   \n",
              "65  LSTM      50       3      64          16      0.2         0.0500   \n",
              "\n",
              "         mse  epochs  input_size  output_size  \n",
              "24  0.013232    50.0         1.0          NaN  \n",
              "30  0.015424    50.0         1.0          NaN  \n",
              "38  0.017622   200.0         1.0          NaN  \n",
              "20  0.018151    50.0         1.0          NaN  \n",
              "29  0.019764    50.0         1.0          NaN  \n",
              "..       ...     ...         ...          ...  \n",
              "63  1.645080    50.0         8.0          NaN  \n",
              "48  1.765182    50.0         8.0          NaN  \n",
              "49  1.881225    50.0         8.0          NaN  \n",
              "64  1.998019    50.0         8.0          NaN  \n",
              "65  6.861587    50.0         8.0          NaN  \n",
              "\n",
              "[88 rows x 11 columns]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv('results.csv').sort_values('mse')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d30fb5",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9bbfe7a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(x,y, hidden_size = 32, num_layers = 2, dropout_rate = 0.2, input_size = 1, part_train = 0.7, part_valid = 0.2): \n",
        "\n",
        "\n",
        "    test_X = x[int((part_train + part_valid) * len(x)):]\n",
        "    true_Y = y[int((part_train + part_valid) * len(y)):]\n",
        "\n",
        "    test_X = torch.from_numpy(test_X).float().unsqueeze(-1)\n",
        "    test_set = TensorDataset(test_X)\n",
        "    test_loader = DataLoader(test_set, batch_size=1)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
        "    model = LSTMModel(input_size, hidden_size, num_layers).to(device)\n",
        "    model.load_state_dict(torch.load(\"LSTMModel.pth\"))   \n",
        "\n",
        "    result = torch.Tensor().to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for _data in test_loader:\n",
        "        data_X = _data[0].to(device)\n",
        "        pred_X = model(data_X)\n",
        "        cur_pred = torch.squeeze(pred_X, dim=0)\n",
        "        result = torch.cat((result, cur_pred), dim=0)\n",
        "\n",
        "    pred_Y = result.detach().cpu().numpy()\n",
        "    \n",
        "    return pred_Y, true_Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8a287ba",
      "metadata": {},
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4b754b45",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(23047, 1)\n",
            "(23047, 15)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Build the dataset for one day prediction\n",
        "\n",
        "stock_name = 'AAPL'\n",
        "freq = \"1H\"\n",
        "timeWindowToUse = 15\n",
        "\n",
        "if freq == \"1D\":\n",
        "\n",
        "    data = pd.read_csv('./data_stocks/{}.csv'.format(stock_name))\n",
        "\n",
        "    data.ts_event = pd.to_datetime(data.ts_event)\n",
        "    data = data.set_index('ts_event')\n",
        "    df_series = data['close']\n",
        "    part_train = 0.8\n",
        "    part_valid = 0.2\n",
        "\n",
        "\n",
        "elif freq == \"1H\":\n",
        "    data_train = pd.read_csv('train_normalised.csv')\n",
        "    data_train.date = pd.to_datetime(data_train.date)\n",
        "    data_test = pd.read_csv('test_normalised.csv')\n",
        "    data_test.date = pd.to_datetime(data_test.date)\n",
        "\n",
        "    part_train =  len(data_train) / (len(data_train) + len(data_test))\n",
        "    \n",
        "    part_valid = 0.2 * part_train\n",
        "    part_train =  0.8 * part_train\n",
        "\n",
        "    df_series = pd.concat([data_train[\"close_\" + stock_name], data_test[\"close_\" + stock_name]])\n",
        "\n",
        "elif freq == \"1M\":\n",
        "    None\n",
        "\n",
        "\n",
        "df = df_series.to_frame(\"y\").astype(float)\n",
        "for i in range(timeWindowToUse, 0, -1):\n",
        "    df[\"x_{}\".format(i)] = df[\"y\"].shift(i)\n",
        "df.dropna(inplace=True)\n",
        "df\n",
        "\n",
        "y = df[\"y\"].to_numpy().reshape(-1,1)\n",
        "print(np.shape(y))\n",
        "x = df.drop(columns=[\"y\"]).to_numpy()\n",
        "print(np.shape(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "f8ebb15b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Window</th>\n",
              "      <th>layers</th>\n",
              "      <th>hidden</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>mse</th>\n",
              "      <th>epochs</th>\n",
              "      <th>input_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.470739</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.482368</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.552889</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.688171</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.735028</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.838357</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.838983</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.840096</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.121384</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.201981</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Window  layers  hidden  batch_size  dropout  learning_rate  \\\n",
              "67  LSTM      50       3      64          16      0.2         0.0001   \n",
              "60  LSTM      50       3      64          16      0.2         0.0001   \n",
              "61  LSTM      50       3      64          16      0.2         0.0005   \n",
              "0   LSTM      50       3      64          16      0.2         0.0010   \n",
              "62  LSTM      50       3      64          16      0.2         0.0010   \n",
              "..   ...     ...     ...     ...         ...      ...            ...   \n",
              "11  LSTM      15       3      32          16      0.2         0.0050   \n",
              "3   LSTM      15       3      32          16      0.2         0.0050   \n",
              "2   LSTM      15       2      32          16      0.2         0.0050   \n",
              "8   LSTM      15       3      32          16      0.2         0.0050   \n",
              "4   LSTM      15       4      32          16      0.2         0.0050   \n",
              "\n",
              "         mse  epochs  input_size  \n",
              "67  0.470739    50.0         8.0  \n",
              "60  0.482368    50.0         8.0  \n",
              "61  0.552889    50.0         8.0  \n",
              "0   0.688171   100.0         8.0  \n",
              "62  0.735028    50.0         8.0  \n",
              "..       ...     ...         ...  \n",
              "11  0.838357    50.0         1.0  \n",
              "3   0.838983     5.0         1.0  \n",
              "2   0.840096     5.0         1.0  \n",
              "8   1.121384    50.0         1.0  \n",
              "4   1.201981     5.0         1.0  \n",
              "\n",
              "[68 rows x 10 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv('results.csv').sort_values(by=['input_size', 'mse'], ascending=[False, True])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "78fdd71a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['close_AAPL', 'close_AMZN', 'close_MSFT', 'close_META', 'close_GOOGL',\n",
            "       'close_NVDA', 'close_SPY', 'close_GM'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[[-2.89970416, -0.36111035, -0.67415835, ..., -0.44697421,\n",
              "         -1.16466404, -1.37312875],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        ...,\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan]],\n",
              "\n",
              "       [[-2.86656585, -0.3615078 , -0.68746649, ..., -0.46016682,\n",
              "         -1.17224645, -1.37133745],\n",
              "        [-2.89970416, -0.36111035, -0.67415835, ..., -0.44697421,\n",
              "         -1.16466404, -1.37312875],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        ...,\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan]],\n",
              "\n",
              "       [[-2.93915452, -0.36200219, -0.71545949, ..., -0.47054303,\n",
              "         -1.2226153 , -1.4008939 ],\n",
              "        [-2.86656585, -0.3615078 , -0.68746649, ..., -0.46016682,\n",
              "         -1.17224645, -1.37133745],\n",
              "        [-2.89970416, -0.36111035, -0.67415835, ..., -0.44697421,\n",
              "         -1.16466404, -1.37312875],\n",
              "        ...,\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan],\n",
              "        [        nan,         nan,         nan, ...,         nan,\n",
              "                 nan,         nan]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 3.42497824, -0.26738998,  7.90684213, ..., 10.80469232,\n",
              "          6.41611977,  0.72806587],\n",
              "        [ 3.42497824, -0.26771957,  7.8398425 , ..., 10.79387142,\n",
              "          6.39662215,  0.77105706],\n",
              "        [ 3.42340022, -0.26801039,  7.82102753, ..., 10.74584438,\n",
              "          6.39012295,  0.76747446],\n",
              "        ...,\n",
              "        [ 3.65694638, -0.26664355,  7.86141087, ..., 10.83404218,\n",
              "          6.51956549,  0.74777017],\n",
              "        [ 3.67588256, -0.2668859 ,  7.85911636, ..., 10.84323253,\n",
              "          6.56235194,  0.77463966],\n",
              "        [ 3.67588256, -0.26650784,  7.90454762, ..., 10.92742807,\n",
              "          6.59322318,  0.79255266]],\n",
              "\n",
              "       [[ 3.40446405, -0.26748692,  7.90821883, ..., 10.78319874,\n",
              "          6.41070377,  0.72985717],\n",
              "        [ 3.42497824, -0.26738998,  7.90684213, ..., 10.80469232,\n",
              "          6.41611977,  0.72806587],\n",
              "        [ 3.42497824, -0.26771957,  7.8398425 , ..., 10.79387142,\n",
              "          6.39662215,  0.77105706],\n",
              "        ...,\n",
              "        [ 3.44470342, -0.26756447,  7.89468124, ..., 11.00569435,\n",
              "          6.51739909,  0.76747446],\n",
              "        [ 3.65694638, -0.26664355,  7.86141087, ..., 10.83404218,\n",
              "          6.51956549,  0.74777017],\n",
              "        [ 3.67588256, -0.2668859 ,  7.85911636, ..., 10.84323253,\n",
              "          6.56235194,  0.77463966]],\n",
              "\n",
              "       [[ 3.39815199, -0.26738998,  7.90225311, ..., 10.78023411,\n",
              "          6.41557817,  0.72269197],\n",
              "        [ 3.40446405, -0.26748692,  7.90821883, ..., 10.78319874,\n",
              "          6.41070377,  0.72985717],\n",
              "        [ 3.42497824, -0.26738998,  7.90684213, ..., 10.80469232,\n",
              "          6.41611977,  0.72806587],\n",
              "        ...,\n",
              "        [ 3.40446405, -0.26773896,  7.88527375, ..., 10.86442965,\n",
              "          6.42207738,  0.74239627],\n",
              "        [ 3.44470342, -0.26756447,  7.89468124, ..., 11.00569435,\n",
              "          6.51739909,  0.76747446],\n",
              "        [ 3.65694638, -0.26664355,  7.86141087, ..., 10.83404218,\n",
              "          6.51956549,  0.74777017]]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('test_normalised.csv')\n",
        "df = df[df.columns[4::6]]\n",
        "print(df.columns)\n",
        "tab = np.array([df.shift(i).to_numpy() for i in range(10)])\n",
        "\n",
        "tab = np.concatenate(tab, axis=1).reshape(-1, 10, 8)\n",
        "tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "fdfc2ed0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Window</th>\n",
              "      <th>layers</th>\n",
              "      <th>hidden</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>mse</th>\n",
              "      <th>epochs</th>\n",
              "      <th>input_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.448719</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.470739</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.482368</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.498594</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.546594</td>\n",
              "      <td>150.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.552889</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.581862</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.608196</td>\n",
              "      <td>200.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.688171</td>\n",
              "      <td>100.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.735028</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.767279</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.808355</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.834365</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.874831</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.887232</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.921945</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.045217</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>128</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.091249</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.095762</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.228884</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.242994</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.408197</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.517202</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.642673</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.645080</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.765182</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.881225</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.998019</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0500</td>\n",
              "      <td>6.861587</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.013232</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Window  layers  hidden  batch_size  dropout  learning_rate  \\\n",
              "71  LSTM      50       3      64           8      0.2         0.0001   \n",
              "67  LSTM      50       3      64          16      0.2         0.0001   \n",
              "60  LSTM      50       3      64          16      0.2         0.0001   \n",
              "68  LSTM      50       3      64          16      0.2         0.0001   \n",
              "69  LSTM      50       3      64          16      0.2         0.0001   \n",
              "61  LSTM      50       3      64          16      0.2         0.0005   \n",
              "72  LSTM      50       3      64          16      0.2         0.0001   \n",
              "70  LSTM      50       3      64          16      0.2         0.0001   \n",
              "0   LSTM      50       3      64          16      0.2         0.0010   \n",
              "62  LSTM      50       3      64          16      0.2         0.0010   \n",
              "51  LSTM      15       3      32          16      0.2         0.0050   \n",
              "47  LSTM      15       3      32          16      0.2         0.0050   \n",
              "52  LSTM      15       3      64          16      0.2         0.0050   \n",
              "46  LSTM      15       2      32          16      0.2         0.0050   \n",
              "66  LSTM      50       3      64          16      0.2         0.0001   \n",
              "54  LSTM       5       3      64          16      0.2         0.0050   \n",
              "57  LSTM      30       3      64          16      0.2         0.0050   \n",
              "53  LSTM      15       3     128          16      0.2         0.0050   \n",
              "56  LSTM      15       3      64          16      0.2         0.0050   \n",
              "58  LSTM      50       3      64          16      0.2         0.0050   \n",
              "45  LSTM      15       1      32          16      0.0         0.0050   \n",
              "59  LSTM     100       3      64          16      0.2         0.0050   \n",
              "50  LSTM      15       3      16          16      0.2         0.0050   \n",
              "55  LSTM      10       3      64          16      0.2         0.0050   \n",
              "63  LSTM      50       3      64          16      0.2         0.0050   \n",
              "48  LSTM      15       4      32          16      0.2         0.0050   \n",
              "49  LSTM      15       3       8          16      0.2         0.0050   \n",
              "64  LSTM      50       3      64          16      0.2         0.0100   \n",
              "65  LSTM      50       3      64          16      0.2         0.0500   \n",
              "24  LSTM      15       1      64          16      0.0         0.0050   \n",
              "\n",
              "         mse  epochs  input_size  \n",
              "71  0.448719    50.0         8.0  \n",
              "67  0.470739    50.0         8.0  \n",
              "60  0.482368    50.0         8.0  \n",
              "68  0.498594   100.0         8.0  \n",
              "69  0.546594   150.0         8.0  \n",
              "61  0.552889    50.0         8.0  \n",
              "72  0.581862    50.0         8.0  \n",
              "70  0.608196   200.0         8.0  \n",
              "0   0.688171   100.0         8.0  \n",
              "62  0.735028    50.0         8.0  \n",
              "51  0.767279    50.0         8.0  \n",
              "47  0.808355    50.0         8.0  \n",
              "52  0.834365    50.0         8.0  \n",
              "46  0.874831    50.0         8.0  \n",
              "66  0.887232    10.0         8.0  \n",
              "54  0.921945    50.0         8.0  \n",
              "57  1.045217    50.0         8.0  \n",
              "53  1.091249    50.0         8.0  \n",
              "56  1.095762    50.0         8.0  \n",
              "58  1.228884    50.0         8.0  \n",
              "45  1.242994    50.0         8.0  \n",
              "59  1.408197    50.0         8.0  \n",
              "50  1.517202    50.0         8.0  \n",
              "55  1.642673    50.0         8.0  \n",
              "63  1.645080    50.0         8.0  \n",
              "48  1.765182    50.0         8.0  \n",
              "49  1.881225    50.0         8.0  \n",
              "64  1.998019    50.0         8.0  \n",
              "65  6.861587    50.0         8.0  \n",
              "24  0.013232    50.0         1.0  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = pd.read_csv('results.csv').sort_values(by=['input_size', 'mse'], ascending=[False, True]).head(30)\n",
        "a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1c3c231a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/150 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [10:06<00:00,  4.04s/it]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0186012150581231\n"
          ]
        }
      ],
      "source": [
        "# try a model\n",
        "bc = 16\n",
        "hidden = 32\n",
        "layers = 1\n",
        "dropout = 0.1\n",
        "lr = 0.005\n",
        "\n",
        "train_model(x,y, batch_size=bc,hidden_size = hidden, num_layers = layers, dropout_rate = dropout, learning_rate = lr, part_train = part_train, part_valid = part_valid)\n",
        "pred_Y, true_Y = test_model(x,y, hidden_size = hidden, num_layers = layers, dropout_rate = dropout, part_train = part_train, part_valid = part_valid)\n",
        "mse = mean_squared_error(true_Y, pred_Y)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aa13b52c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.015799871912870113\n"
          ]
        }
      ],
      "source": [
        "pred_Y, true_Y = test_model(x,y, hidden_size = hidden, num_layers = layers, dropout_rate = dropout, part_train = part_train, part_valid = part_valid)\n",
        "mse = mean_squared_error(true_Y, pred_Y)\n",
        "print(mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "02f980e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Window</th>\n",
              "      <th>layers</th>\n",
              "      <th>hidden</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>dropout</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>mse</th>\n",
              "      <th>epochs</th>\n",
              "      <th>input_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.013232</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.015424</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.017622</td>\n",
              "      <td>200.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.018151</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.019764</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.645080</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.765182</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>1.881225</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1.998019</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>64</td>\n",
              "      <td>16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0500</td>\n",
              "      <td>6.861587</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model  Window  layers  hidden  batch_size  dropout  learning_rate  \\\n",
              "24  LSTM      15       1      64          16      0.0         0.0050   \n",
              "30  LSTM      15       1      64          16      0.0         0.0010   \n",
              "38  LSTM      15       1      64          16      0.0         0.0050   \n",
              "20  LSTM      15       1      64          16      0.0         0.0050   \n",
              "29  LSTM      15       1      64          16      0.0         0.0005   \n",
              "..   ...     ...     ...     ...         ...      ...            ...   \n",
              "63  LSTM      50       3      64          16      0.2         0.0050   \n",
              "48  LSTM      15       4      32          16      0.2         0.0050   \n",
              "49  LSTM      15       3       8          16      0.2         0.0050   \n",
              "64  LSTM      50       3      64          16      0.2         0.0100   \n",
              "65  LSTM      50       3      64          16      0.2         0.0500   \n",
              "\n",
              "         mse  epochs  input_size  \n",
              "24  0.013232    50.0         1.0  \n",
              "30  0.015424    50.0         1.0  \n",
              "38  0.017622   200.0         1.0  \n",
              "20  0.018151    50.0         1.0  \n",
              "29  0.019764    50.0         1.0  \n",
              "..       ...     ...         ...  \n",
              "63  1.645080    50.0         8.0  \n",
              "48  1.765182    50.0         8.0  \n",
              "49  1.881225    50.0         8.0  \n",
              "64  1.998019    50.0         8.0  \n",
              "65  6.861587    50.0         8.0  \n",
              "\n",
              "[72 rows x 10 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv('results.csv').sort_values(by='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "7bd9cf19",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.47096672855229854"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "a = pd.read_csv('test_normalised.csv')\n",
        "a = a[\"close_AAPL\"]\n",
        "mean_squared_error(a[:-50], a[50:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "e0920557",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:06<00:30,  2.68it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1723989432624085e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 52/100 [00:17<00:16,  2.90it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.332262930686459e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [00:21<00:13,  2.90it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.952083269740195e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [00:20<00:13,  2.90it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.487318047782164e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [00:07<00:27,  2.83it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.192973593205392e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:13<00:20,  2.91it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.40737792353439e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:09<00:25,  2.87it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.373807512177333e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 43/100 [00:14<00:19,  2.92it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.409817483352008e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 56/100 [00:21<00:16,  2.59it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.386642391994144e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:12<00:29,  2.40it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.122483967775784e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 40/100 [00:15<00:22,  2.65it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.120300072593945e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 55/100 [00:21<00:17,  2.58it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.365206332098568e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:17<00:31,  2.03it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.396681061844523e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [00:18<00:27,  2.17it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.25872375248053e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [00:19<00:24,  2.27it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.426036969100071e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 51/100 [00:22<00:21,  2.29it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.18340647287689e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:24<00:41,  1.51it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.415757747674821e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [00:29<00:35,  1.53it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.321855999653327e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:12<00:55,  1.49it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1788199903694787e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:17<00:48,  1.51it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.948694369842739e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [00:10<00:55,  1.52it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.429997499528236e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:30<00:32,  1.58it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.588754663094841e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 20/100 [00:13<00:52,  1.51it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2463078776785762e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:24<00:41,  1.52it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.889431785345876e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:21<00:41,  1.59it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.859454970572276e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 52/100 [00:32<00:29,  1.61it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.412390336783402e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [00:13<00:51,  1.53it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0542383648636254e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:21<00:42,  1.56it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.490138644226982e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [00:22<00:49,  1.40it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.710026382305457e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:27<00:43,  1.41it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.264307103286992e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:23<00:48,  1.38it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.293755140325499e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [00:33<00:37,  1.40it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.884773424792076e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:52<02:22,  1.96s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0292811278765045e+21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 44/100 [00:36<00:46,  1.19it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.629710679487919e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:15<01:12,  1.14it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.068817881539655e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:20<01:05,  1.15it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.247102803302409e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [00:32<02:50,  2.03s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3787196891346966e+21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [01:03<01:09,  1.33s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.389478656890913e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 71/100 [04:44<01:56,  4.00s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.109559165364495e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [00:42<01:33,  1.36s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.558310532574482e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:33<01:02,  1.03it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1933599286436768e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:42<00:50,  1.07it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.878577114951249e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:22<01:12,  1.05it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1630747250176907e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:28<01:06,  1.05it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3451339853318994e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:38<00:53,  1.09it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.959923520144504e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 56/100 [00:49<00:39,  1.12it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.185296188225938e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:24<01:07,  1.08it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.584097470472791e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 22/100 [00:20<01:12,  1.07it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.7283116106661845e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 32/100 [00:34<01:13,  1.08s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9149870404202614e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [01:03<00:40,  1.05s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.437937047084937e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 56/100 [00:59<00:47,  1.07s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.379031726304186e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [00:30<01:18,  1.09s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.048045317913615e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:38<01:30,  1.29s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.832009130707464e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:45<01:24,  1.31s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.544043288939519e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 43/100 [01:02<01:23,  1.46s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.628935193550296e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:35<01:36,  1.32s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.765653606304243e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 23/100 [01:53<06:21,  4.95s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.814021529265054e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 22/100 [00:47<02:48,  2.16s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.319198049737188e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [01:58<06:16,  4.95s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2113713406774034e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [33:11<47:45, 48.57s/it]    \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.735552614920431e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:06<00:12,  5.22it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:16,  5.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.562382944158393e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 62/100 [00:09<00:05,  6.41it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:12,  7.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.404682233641883e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:04<00:08,  7.51it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:13,  7.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.36688514828928e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 49/100 [00:06<00:06,  7.54it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:12,  8.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.909238175574601e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 53/100 [00:07<00:07,  6.68it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:14,  6.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.251045282080182e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 68/100 [00:13<00:06,  5.09it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.401711113391627e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:09<00:12,  4.62it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.640865439120378e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 85/100 [00:16<00:02,  5.30it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:17,  5.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.656441023229509e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:07<00:09,  5.82it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:15,  6.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.720282740049847e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 62/100 [00:10<00:06,  6.10it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:14,  6.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.869019978680709e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:02<00:12,  6.37it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:14,  6.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.590465818276917e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 62/100 [00:09<00:05,  6.65it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.58347135724396e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 68/100 [00:17<00:08,  3.87it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.039730023364649e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [00:12<00:14,  3.68it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.394425648198202e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 55/100 [00:14<00:11,  3.78it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.022581692897314e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 58/100 [00:14<00:10,  4.06it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.216453722456226e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 44/100 [00:23<00:29,  1.89it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.728517027589544e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 87/100 [17:00<02:32, 11.73s/it]   \n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.808404962435128e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:57<01:51,  1.69s/it]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.386523173965443e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 52/100 [00:27<00:25,  1.90it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.202016732795787e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 43/100 [00:12<00:17,  3.34it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.028838390634352e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:24<00:00,  4.15it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.736097399322534e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:04<00:19,  4.28it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.685706337483848e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [00:15<00:09,  4.05it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.145009439946363e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:11<00:19,  3.29it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.873947519213724e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 95/100 [00:27<00:01,  3.50it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.793246973168032e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:09<00:17,  3.78it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.911899075165961e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [15:47<10:05, 15.53s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1800499842736364e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [18:13<26:13, 26.68s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.560638478351759e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 63/100 [19:10<11:15, 18.25s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.487045204333701e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [01:13<01:29,  1.63s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1345579201652374e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 56/100 [00:19<00:15,  2.82it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0968847342452105e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 32/100 [00:21<00:44,  1.52it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.389564265245289e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 61/100 [01:06<00:42,  1.08s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.877454942384017e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [00:17<01:30,  1.08s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.108201946559511e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 86/100 [01:09<00:11,  1.23it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.606646939523025e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [01:15<06:09,  4.46s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.131151189821971e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 62/100 [01:17<00:47,  1.24s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.27900098790304e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 58/100 [38:05<27:34, 39.40s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0139749018307692e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [01:06<01:06,  1.34s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.247904960976994e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:09<00:23,  2.99it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0085502312310315e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 66/100 [00:21<00:11,  3.02it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.657893062083876e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:07<00:33,  2.44it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8392942556965759e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 77/100 [00:32<00:09,  2.39it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.142439819292141e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [00:18<00:20,  2.54it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.502680548729695e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 97/100 [00:32<00:01,  2.94it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.918114257449554e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [00:12<00:18,  3.25it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.996567550414539e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:12<00:25,  2.65it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.995010105970973e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:21<00:39,  1.65it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.7002554459427547e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:51<00:00,  1.95it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.672923099677619e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:16<00:28,  2.22it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0986390747978844e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 57/100 [17:01<12:50, 17.93s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0824886352894974e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [19:21<37:34, 34.16s/it]  \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2078504738203353e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 43/100 [00:29<00:38,  1.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.377780948580362e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [16:23<36:29, 31.73s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.348218182657432e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 93/100 [02:16<00:10,  1.46s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.522855466606004e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [01:08<02:18,  2.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.5974132097165754e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 67/100 [10:34<05:12,  9.47s/it]   \n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.49695037269725e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [33:22<1:45:42, 83.45s/it] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5071365699796648e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [01:36<03:44,  3.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.069652897890093e+18\n"
          ]
        }
      ],
      "source": [
        "# Compute the results\n",
        "results = pd.read_csv('LSTM_results.csv')\n",
        "\n",
        "for bc in [16,64]:\n",
        "    for layers in [1,2,3]:\n",
        "        for hidden in [8,16,32,64,128]:\n",
        "            for dropout in [0, 0.1]:\n",
        "                for lr in [0.05, 0.01]:\n",
        "                    if len(results[(results['Window'] == timeWindowToUse) & (results['layers'] == layers) & (results['hidden'] == hidden) & (results['batch_size'] == bc) & (results['dropout'] == dropout) & (results['lr'] == lr)]) > 0:\n",
        "                        continue\n",
        "                    train_model(x,y, batch_size=bc,hidden_size = hidden, num_layers = layers, dropout_rate = dropout, learning_rate = lr)\n",
        "                    pred_Y, true_Y = test_model(x,y, hidden_size = hidden, num_layers = layers, dropout_rate = dropout)\n",
        "                    mse = mean_squared_error(scaler_y.inverse_transform(true_Y.reshape(-1, 1)), scaler_y.inverse_transform(pred_Y.reshape(-1, 1)))\n",
        "                    print(mse)\n",
        "                    results = pd.concat([results, pd.DataFrame.from_records([{'Window': timeWindowToUse,'layers': layers,\n",
        "                                         'hidden': hidden, 'batch_size' : bc,'dropout': dropout, 'lr': lr, 'mse': mse}])])\n",
        "                    results.to_csv('LSTM_results.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

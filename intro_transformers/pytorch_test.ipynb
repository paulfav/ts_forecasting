{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.9971, -1.3775, -0.1383],\n",
      "        [-0.4282,  1.2077, -0.9334],\n",
      "        [-0.8660,  0.7462, -0.5380],\n",
      "        [ 0.0000,  0.0000,  0.0000]], requires_grad=True)\n",
      "tensor([[ 1.6437, -1.1337, -0.1138],\n",
      "        [-0.4282,  1.2077, -0.9334]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tens= torch.tensor([0,1]) #this will just return the first and second row of the embedding matrix\n",
    "\n",
    "emb = nn.Embedding(4, 3, 3, 2)\n",
    "print(emb.weight)\n",
    "\n",
    "a = emb(tens)\n",
    "\n",
    "print( a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "[[[1. 2. 3.]\n",
      "  [4. 5. 6.]]]\n",
      "tensor([[[1., 2., 3.]],\n",
      "\n",
      "        [[4., 5., 6.]]])\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.]],\n",
      "\n",
      "        [[4.],\n",
      "         [5.],\n",
      "         [6.]]])\n",
      "tensor([[[1., 2., 3.]],\n",
      "\n",
      "        [[4., 5., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "position = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "print(position)\n",
    "position0 = np.array(position.unsqueeze(0))\n",
    "print(position0)\n",
    "position1 = position.unsqueeze(1)\n",
    "print(position1)\n",
    "position_1 = position.unsqueeze(-1)\n",
    "print(position_1)\n",
    "position_2 = position.unsqueeze(-2)\n",
    "print(position_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class InputEmbeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model:int, vocab_size : int): #the dimension of the model and the vocab_size\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding= nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float ) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        #create a matrix of siez (seq_len, d_model) \n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        print(position)\n",
    "        print(position.shape)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-4*torch.log(torch.tensor(10.0)) / d_model))\n",
    "        print(div_term)\n",
    "        print(div_term.shape)\n",
    "        print(position * div_term)\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        print(pe)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.]])\n",
      "torch.Size([8, 1])\n",
      "tensor([1.0000, 0.0100])\n",
      "torch.Size([2])\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [1.0000, 0.0100],\n",
      "        [2.0000, 0.0200],\n",
      "        [3.0000, 0.0300],\n",
      "        [4.0000, 0.0400],\n",
      "        [5.0000, 0.0500],\n",
      "        [6.0000, 0.0600],\n",
      "        [7.0000, 0.0700]])\n",
      "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "        [-0.7568, -0.6536,  0.0400,  0.9992],\n",
      "        [-0.9589,  0.2837,  0.0500,  0.9988],\n",
      "        [-0.2794,  0.9602,  0.0600,  0.9982],\n",
      "        [ 0.6570,  0.7539,  0.0699,  0.9976]])\n",
      "tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "         [-0.7568, -0.6536,  0.0400,  0.9992],\n",
      "         [-0.9589,  0.2837,  0.0500,  0.9988],\n",
      "         [-0.2794,  0.9602,  0.0600,  0.9982],\n",
      "         [ 0.6570,  0.7539,  0.0699,  0.9976]]])\n"
     ]
    }
   ],
   "source": [
    "posi_embed = PositionalEncoding(4, 8, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "yrU0iWdalVGx",
      "metadata": {
        "id": "yrU0iWdalVGx"
      },
      "source": [
        "# Import all the required libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4189cf86",
      "metadata": {
        "id": "4189cf86",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import torch\n",
        "from torch.nn import Module, GRU, Linear\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c5f71e4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "c5f71e4e",
        "outputId": "047bd0e5-7e20-4d32-8d6f-0a0c1c5a2983"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ts_event\n",
              "2018-05-01    175200000000\n",
              "2018-05-02    176500000000\n",
              "2018-05-03    176900000000\n",
              "2018-05-04    184100000000\n",
              "2018-05-07    185000000000\n",
              "                  ...     \n",
              "2024-01-22    193890000000\n",
              "2024-01-23    195110000000\n",
              "2024-01-24    194000000000\n",
              "2024-01-25    194080000000\n",
              "2024-01-26    192180000000\n",
              "Name: close, Length: 1445, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stock_name = 'AAPL'\n",
        "\n",
        "data = pd.read_csv('./data_stocks/{}.csv'.format(stock_name))\n",
        "\n",
        "data.ts_event = pd.to_datetime(data.ts_event)\n",
        "data = data.set_index('ts_event')\n",
        "df_series = data['close']\n",
        "df_series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7df385e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1430,)\n",
            "(1430, 15)\n",
            "(1430, 1)\n",
            "(1430, 15)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Build the dataset\n",
        "\n",
        "timeWindowToUse = 15\n",
        "df = df_series.to_frame(\"y\").astype(float)\n",
        "for i in range(timeWindowToUse, 0, -1):\n",
        "    df[\"x_{}\".format(i)] = df[\"y\"].shift(i)\n",
        "df.dropna(inplace=True)\n",
        "df\n",
        "\n",
        "y = df[\"y\"].to_numpy()\n",
        "print(np.shape(y))\n",
        "x = df.drop(columns=[\"y\"]).to_numpy()\n",
        "print(np.shape(x))\n",
        "\n",
        "scaler_x = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler_y = MinMaxScaler(feature_range=(-1,1))\n",
        "y_unscaled = df.to_numpy()[:,0].reshape(-1,1)\n",
        "x_unscaled = df.to_numpy()[:,1:]\n",
        "y = scaler_y.fit_transform(y_unscaled)\n",
        "x = scaler_x.fit_transform(x_unscaled)\n",
        "\n",
        "print(np.shape(y))\n",
        "print(np.shape(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dsMIlQ8DnVOJ",
      "metadata": {
        "id": "dsMIlQ8DnVOJ"
      },
      "source": [
        "# ML Model (LSTM)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01a7fb77",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate=0.2):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
        "        out, _ = self.gru(x, h0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2840da90",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(x,y, batch_size = 64, hidden_size = 32, num_layers = 2, dropout_rate = 0.2, learning_rate = 0.001,input_size = 1): \n",
        "    epoch = 100\n",
        "\n",
        "    part_train = 0.7\n",
        "    part_valid = 0.2\n",
        "    use_cuda = True\n",
        "\n",
        "    # Data loading\n",
        "    train_X = x[:int(part_train * len(x))]\n",
        "    train_Y = y[:int(part_train * len(y))]\n",
        "    valid_X = x[int(part_train * len(x)): int(part_train * len(x)) + int(part_valid * len(x))]\n",
        "    valid_Y = y[int(part_train * len(y)): int(part_train * len(y)) + int(part_valid * len(y))]\n",
        "\n",
        "    train_X, train_Y = torch.from_numpy(train_X).float().unsqueeze(-1), torch.from_numpy(train_Y).float()\n",
        "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=batch_size, shuffle=True)    \n",
        "\n",
        "    valid_X, valid_Y = torch.from_numpy(valid_X).float().unsqueeze(-1), torch.from_numpy(valid_Y).float()\n",
        "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=batch_size)\n",
        "\n",
        "    # Training parameters\n",
        "    device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\") \n",
        "    model = GRUModel(input_size, hidden_size, num_layers, dropout_rate=dropout_rate).to(device)      \n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    valid_loss_min = float(\"inf\")\n",
        "    bad_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    train_loss_array_per_epoch = []\n",
        "    valid_loss_array_per_epoch = []\n",
        "\n",
        "    # Training epochs\n",
        "    for epoch in tqdm(range(epoch)):\n",
        "        model.train(True)                  \n",
        "        train_loss_array = []\n",
        "        hidden_train = None\n",
        "\n",
        "        #Train phase\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            batch_x, batch_y = batch[0].to(device), batch[1].to(device)\n",
        "            pred_y = model(batch_x) \n",
        "\n",
        "            optimizer.zero_grad()               \n",
        "            loss = criterion(pred_y, batch_y)  \n",
        "            loss.backward()                     \n",
        "            optimizer.step()     \n",
        "\n",
        "            train_loss_array.append(loss.item())\n",
        "            global_step += 1\n",
        "                \n",
        "        #Eval phase\n",
        "        model.eval()                    \n",
        "        valid_loss_array = []\n",
        "\n",
        "        for i, batch in enumerate(valid_loader):\n",
        "            batch_v_x , batch_v_y= batch[0].to(device), batch[1].to(device)\n",
        "            pred_Y= model(batch_v_x)\n",
        "\n",
        "            loss = criterion(pred_Y, batch_v_y)  \n",
        "\n",
        "            valid_loss_array.append(loss.item())\n",
        "\n",
        "        train_loss_cur = np.mean(train_loss_array)\n",
        "        valid_loss_cur = np.mean(valid_loss_array)\n",
        "        train_loss_array_per_epoch.append(train_loss_cur)\n",
        "        valid_loss_array_per_epoch.append(valid_loss_cur)\n",
        "        \n",
        "\n",
        "        # Save if better\n",
        "        if valid_loss_cur < valid_loss_min:\n",
        "            valid_loss_min = valid_loss_cur\n",
        "            bad_epoch = 0\n",
        "            torch.save(model.state_dict(),\"GRUModel.pth\")\n",
        "        else:\n",
        "            bad_epoch += 1\n",
        "            if bad_epoch > 15:\n",
        "                break\n",
        "        \n",
        "        plt.plot(train_loss_array_per_epoch, label='Training loss')\n",
        "        plt.plot(valid_loss_array_per_epoch, label='Validation loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3fc55843",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 57/100 [00:29<00:22,  1.94it/s]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def train_model(x,y, batch_size = 64, hidden_size = 32, num_layers = 2, dropout_rate = 0.2, learning_rate = 0.001,input_size = 1): \n",
        "    epoch = 100\n",
        "\n",
        "    part_train = 0.7\n",
        "    part_valid = 0.2\n",
        "    use_cuda = True\n",
        "\n",
        "    # Data loading\n",
        "    train_X = x[:int(part_train * len(x))]\n",
        "    train_Y = y[:int(part_train * len(y))]\n",
        "    valid_X = x[int(part_train * len(x)): int(part_train * len(x)) + int(part_valid * len(x))]\n",
        "    valid_Y = y[int(part_train * len(y)): int(part_train * len(y)) + int(part_valid * len(y))]\n",
        "\n",
        "    train_X, train_Y = torch.from_numpy(train_X).float().unsqueeze(-1), torch.from_numpy(train_Y).float()\n",
        "    train_loader = DataLoader(TensorDataset(train_X, train_Y), batch_size=batch_size, shuffle=True)    \n",
        "\n",
        "    valid_X, valid_Y = torch.from_numpy(valid_X).float().unsqueeze(-1), torch.from_numpy(valid_Y).float()\n",
        "    valid_loader = DataLoader(TensorDataset(valid_X, valid_Y), batch_size=batch_size)\n",
        "\n",
        "    # Training parameters\n",
        "    device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\") \n",
        "    model = GRUModel(input_size, hidden_size, num_layers, dropout_rate=dropout_rate).to(device)      \n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    valid_loss_min = float(\"inf\")\n",
        "    bad_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    train_loss_array_per_epoch = []\n",
        "    valid_loss_array_per_epoch = []\n",
        "\n",
        "    # Training epochs\n",
        "    for epoch in tqdm(range(epoch)):\n",
        "        model.train(True)                  \n",
        "        train_loss_array = []\n",
        "        hidden_train = None\n",
        "\n",
        "        #Train phase\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            batch_x, batch_y = batch[0].to(device), batch[1].to(device)\n",
        "            pred_y = model(batch_x) \n",
        "\n",
        "            optimizer.zero_grad()               \n",
        "            loss = criterion(pred_y, batch_y)  \n",
        "            loss.backward()                     \n",
        "            optimizer.step()     \n",
        "\n",
        "            train_loss_array.append(loss.item())\n",
        "            global_step += 1\n",
        "                \n",
        "        #Eval phase\n",
        "        model.eval()                    \n",
        "        valid_loss_array = []\n",
        "\n",
        "        for i, batch in enumerate(valid_loader):\n",
        "            batch_v_x , batch_v_y= batch[0].to(device), batch[1].to(device)\n",
        "            pred_Y= model(batch_v_x)\n",
        "\n",
        "            loss = criterion(pred_Y, batch_v_y)  \n",
        "\n",
        "            valid_loss_array.append(loss.item())\n",
        "\n",
        "        train_loss_cur = np.mean(train_loss_array)\n",
        "        valid_loss_cur = np.mean(valid_loss_array)\n",
        "        train_loss_array_per_epoch.append(train_loss_cur)\n",
        "        valid_loss_array_per_epoch.append(valid_loss_cur)\n",
        "        \n",
        "\n",
        "        # Save if better\n",
        "        if valid_loss_cur < valid_loss_min:\n",
        "            valid_loss_min = valid_loss_cur\n",
        "            bad_epoch = 0\n",
        "            torch.save(model.state_dict(),\"GRUModel.pth\")\n",
        "        else:\n",
        "            bad_epoch += 1\n",
        "            if bad_epoch > 15:\n",
        "                break\n",
        "        \n",
        "    # plt.plot(train_loss_array_per_epoch, label='Training loss')\n",
        "    # plt.plot(valid_loss_array_per_epoch, label='Validation loss')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "\n",
        "train_model(x,y,batch_size=16, hidden_size=128, num_layers=1, dropout_rate=0.1, learning_rate=0.001,input_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d30fb5",
      "metadata": {},
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9bbfe7a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(x,y, hidden_size = 32, num_layers = 2, dropout_rate = 0.2, input_size = 1): \n",
        "    use_cuda = True\n",
        "    part_train = 0.7\n",
        "    part_valid = 0.2\n",
        "\n",
        "    test_X = x[int((part_train + part_valid) * len(x)):]\n",
        "    true_Y = y[int((part_train + part_valid) * len(y)):]\n",
        "\n",
        "    test_X = torch.from_numpy(test_X).float().unsqueeze(-1)\n",
        "    test_set = TensorDataset(test_X)\n",
        "    test_loader = DataLoader(test_set, batch_size=1)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
        "    model = GRUModel(input_size, hidden_size, num_layers).to(device)\n",
        "    model.load_state_dict(torch.load(\"GRUModel.pth\"))   \n",
        "\n",
        "    result = torch.Tensor().to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for _data in test_loader:\n",
        "        data_X = _data[0].to(device)\n",
        "        pred_X = model(data_X)\n",
        "        cur_pred = torch.squeeze(pred_X, dim=0)\n",
        "        result = torch.cat((result, cur_pred), dim=0)\n",
        "\n",
        "    pred_Y = result.detach().cpu().numpy()\n",
        "    \n",
        "    return pred_Y, true_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e0920557",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:07<00:23,  3.14it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.085881807617991e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:12<00:20,  3.05it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.479007117175438e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 22/100 [00:06<00:23,  3.32it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.203361935921848e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:10<00:18,  3.55it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.748623922583235e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:10<00:18,  3.44it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.454502052844843e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:09<00:19,  3.41it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.799990742332547e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:11<00:18,  3.35it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.110639702553265e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 22/100 [00:07<00:25,  3.06it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.930423978337109e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [00:07<00:36,  2.29it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.862385258548998e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 63/100 [00:19<00:11,  3.30it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.896108528244666e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:07<00:22,  3.31it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.570710578440569e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:14<00:16,  3.21it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.682838650589356e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:13<00:25,  2.54it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1088322072856537e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 53/100 [00:20<00:18,  2.58it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.008423321850276e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:12<00:23,  2.76it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.252592277846623e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [00:22<00:15,  2.65it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.859086578124661e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:13<00:40,  1.85it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.429605353423271e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 37/100 [00:19<00:32,  1.91it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.979973570799383e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [00:28<00:24,  1.88it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.462496570143248e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [00:18<00:40,  1.69it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.570198343299965e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:27<00:29,  1.74it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.776950135036417e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 23/100 [00:13<00:46,  1.65it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.319916603910173e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 83/100 [00:50<00:10,  1.65it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.765201788706154e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 73/100 [00:39<00:14,  1.83it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2302067260922135e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:13<00:36,  2.02it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.376117925446988e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:14<00:35,  2.02it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.538861989764788e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 17/100 [00:08<00:43,  1.91it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3346551110432938e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [00:26<00:22,  2.03it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1035991884944652e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:22<00:30,  1.90it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.287207798215207e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:19<00:36,  1.80it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.482504687964929e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:16<00:45,  1.59it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.892292103278782e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:22<00:31,  1.85it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.311452134467976e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 22/100 [00:14<00:50,  1.54it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.107828381914543e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:21<00:43,  1.52it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.876916982562321e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:22<00:43,  1.50it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.568595734788191e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:23<00:41,  1.54it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0917008957344332e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:33<01:04,  1.02it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0712428582972349e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:28<01:06,  1.05it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.403610111428483e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [00:50<00:50,  1.02s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.7850840380781717e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:24<01:12,  1.04it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0802402748394912e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 16/100 [00:12<01:03,  1.33it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.325896240024051e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:19<00:54,  1.36it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.523738037347899e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [00:26<00:58,  1.18it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3006119646808492e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:39<00:46,  1.17it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3797137988063898e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [00:35<00:43,  1.25it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4584688024856252e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [00:18<00:59,  1.28it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0358298392290292e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:31<00:56,  1.13it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.0876699604500247e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [00:33<00:48,  1.22it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3789110141461098e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 21/100 [00:20<01:16,  1.03it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.430146095581001e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:31<00:57,  1.12it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2088768687591e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:26<01:01,  1.14it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.1756339082621768e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 51/100 [00:40<00:38,  1.27it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.085044548598458e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [00:18<01:17,  1.04it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1193354988226001e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 55/100 [00:53<00:43,  1.03it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.996623565512377e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:27<01:17,  1.04s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.4504925627251327e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:44<01:10,  1.15s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.227616417966471e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [00:45<01:46,  1.52s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.303534525496339e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [00:50<01:38,  1.50s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.754783328091211e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:37<01:52,  1.49s/it]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.1063854019898966e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [00:44<01:38,  1.43s/it]\n",
            "  2%|▏         | 2/100 [00:00<00:07, 12.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.643616860054792e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:03<00:05, 11.54it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:08, 11.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.162854258593105e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 67/100 [00:07<00:03,  8.94it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:14,  6.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.685823714028466e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:04<00:08,  7.95it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:09, 10.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.502291253774707e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [00:05<00:05,  9.33it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:09, 10.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.646292956043296e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 36/100 [00:03<00:05, 10.77it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:09,  9.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.743275307707561e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 51/100 [00:04<00:04, 11.20it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:08, 12.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.308165131905402e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 18/100 [00:01<00:07, 11.20it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:08, 11.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.842077632717201e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 53/100 [00:05<00:04, 10.30it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:09, 10.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.008525569475726e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:03<00:06,  9.97it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:09, 10.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.096862141260658e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:04<00:05,  9.83it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:09, 10.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.118657703376513e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [00:04<00:05, 10.01it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  2%|▏         | 2/100 [00:00<00:09, 10.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.860030724096525e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [00:05<00:04, 10.30it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:15,  6.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.209002676992359e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 55/100 [00:08<00:06,  6.52it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.05095275691352e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [00:08<00:07,  6.53it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.092861620002213e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [00:05<00:10,  6.44it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:15,  6.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.024832031668263e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [00:07<00:07,  6.58it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.17223570133456e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:05<00:17,  4.23it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.45850943707186e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [00:09<00:13,  4.28it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.223214281793399e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 32/100 [00:07<00:15,  4.29it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.990762733001581e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 33/100 [00:07<00:15,  4.24it/s]\n",
            "/Users/alex/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "  1%|          | 1/100 [00:00<00:14,  7.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.333581700854201e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 65/100 [00:09<00:05,  6.74it/s]\n",
            "  1%|          | 1/100 [00:00<00:14,  6.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.750161992444995e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 73/100 [00:10<00:04,  6.72it/s]\n",
            "  1%|          | 1/100 [00:00<00:14,  6.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.667116039877064e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 98/100 [00:14<00:00,  6.62it/s]\n",
            "  1%|          | 1/100 [00:00<00:15,  6.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.1839941812156e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 27/100 [00:04<00:11,  6.53it/s]\n",
            "  1%|          | 1/100 [00:00<00:15,  6.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.403560148517515e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:04<00:11,  6.30it/s]\n",
            "  1%|          | 1/100 [00:00<00:15,  6.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3486546930053896e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 64/100 [00:09<00:05,  6.49it/s]\n",
            "  1%|          | 1/100 [00:00<00:14,  6.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.918832405567549e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:04<00:11,  6.24it/s]\n",
            "  1%|          | 1/100 [00:00<00:14,  6.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.899092800012274e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 62/100 [00:09<00:05,  6.37it/s]\n",
            "  1%|          | 1/100 [00:00<00:19,  5.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.4835885588356604e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [00:03<00:15,  5.08it/s]\n",
            "  1%|          | 1/100 [00:00<00:17,  5.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.11617424255969e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [00:06<00:11,  5.46it/s]\n",
            "  1%|          | 1/100 [00:00<00:17,  5.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.452465638386012e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 32/100 [00:05<00:12,  5.35it/s]\n",
            "  1%|          | 1/100 [00:00<00:18,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.137470885209559e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 55/100 [00:10<00:08,  5.44it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.678710616264497e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 20/100 [00:06<00:25,  3.12it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0182814218209678e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 41/100 [00:12<00:18,  3.23it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0160195479467299e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [00:11<00:19,  3.18it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2720677675424068e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:14<00:17,  3.17it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1659212049901085e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [00:32<00:21,  1.85it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.263053217334604e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 71/100 [00:38<00:15,  1.84it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.001365883097289e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [00:29<00:35,  1.53it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6177269657659752e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 59/100 [00:32<00:22,  1.81it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.495081981999973e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 23/100 [00:05<00:16,  4.58it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.54533641663946e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:08<00:12,  4.70it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.291432788177964e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 78/100 [00:16<00:04,  4.64it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.238018808976756e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 79/100 [00:16<00:04,  4.66it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.89774007581507e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [00:05<00:17,  4.40it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.761710646161822e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:09<00:13,  4.32it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.922285288452596e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [00:10<00:12,  4.25it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1593588938626376e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:22<00:00,  4.47it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3104603397599484e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 46/100 [00:12<00:14,  3.81it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.8351105384747e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [00:09<00:16,  3.81it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.48942108410635e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 26/100 [00:07<00:20,  3.64it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.609926515550604e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 52/100 [00:13<00:12,  3.72it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0895106006768433e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:13<00:33,  2.10it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.4157377403051385e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [00:18<00:28,  2.13it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.627769138889229e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 28/100 [00:13<00:34,  2.08it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.755452593517617e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [00:13<00:34,  2.08it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.508008794445935e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [00:38<00:46,  1.17it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.126839619977366e+19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 51/100 [00:43<00:41,  1.17it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.558247154410542e+18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 42/100 [00:36<00:50,  1.15it/s]\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.637644857866263e+20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 64/100 [01:03<00:35,  1.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.124967414889111e+19\n"
          ]
        }
      ],
      "source": [
        "# Compute the results\n",
        "results = pd.read_csv('GRU_results.csv')\n",
        "\n",
        "for bc in [16,64]:\n",
        "    for layers in [1,2,3]:\n",
        "        for hidden in [8,16,32,64,128]:\n",
        "            for dropout in [0, 0.1]:\n",
        "                for lr in [0.05, 0.01]:\n",
        "                    if len(results[(results['Window'] == timeWindowToUse) & (results['layers'] == layers) & (results['hidden'] == hidden) & (results['batch_size'] == bc) & (results['dropout'] == dropout) & (results['lr'] == lr)]) > 0:\n",
        "                         continue\n",
        "                    train_model(x,y, batch_size=bc,hidden_size = hidden, num_layers = layers, dropout_rate = dropout, learning_rate = lr)\n",
        "                    pred_Y, true_Y = test_model(x,y, hidden_size = hidden, num_layers = layers, dropout_rate = dropout)\n",
        "                    mse = mean_squared_error(scaler_y.inverse_transform(true_Y.reshape(-1, 1)), scaler_y.inverse_transform(pred_Y.reshape(-1, 1)))\n",
        "                    print(mse)\n",
        "                    results = pd.concat([results, pd.DataFrame.from_records([{'Window': timeWindowToUse,'layers': layers,\n",
        "                                         'hidden': hidden, 'batch_size' : bc,'dropout': dropout, 'lr': lr, 'mse': mse}])])\n",
        "                    results.to_csv('GRU_results.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6MGDYZvrNUYc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MGDYZvrNUYc",
        "outputId": "4c699113-12cb-4065-b162-29e1761b96a4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Window</th>\n",
              "      <th>layers</th>\n",
              "      <th>hidden</th>\n",
              "      <th>dropout</th>\n",
              "      <th>lr</th>\n",
              "      <th>mse</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.214645e+18</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5.462497e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.570198e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.627769e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.646293e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.685824e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.748624e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.799991e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5.842078e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.859087e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.896109e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.918832e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.930424e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.979974e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5.996624e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>6.008526e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>6.085882e+18</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>6.118658e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>6.172236e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.05</td>\n",
              "      <td>6.183994e+18</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Window  layers  hidden  dropout    lr           mse  batch_size\n",
              "0       0.0     0.0     0.0      0.0  0.00  5.214645e+18         0.0\n",
              "19     15.0     1.0   128.0      0.1  0.05  5.462497e+18        16.0\n",
              "20     15.0     1.0   128.0      0.1  0.01  5.570198e+18        16.0\n",
              "114    15.0     3.0    64.0      0.0  0.01  5.627769e+18        64.0\n",
              "64     15.0     1.0     8.0      0.1  0.01  5.646293e+18        64.0\n",
              "62     15.0     1.0     8.0      0.0  0.01  5.685824e+18        64.0\n",
              "4      15.0     1.0     8.0      0.1  0.01  5.748624e+18        16.0\n",
              "6      15.0     1.0    16.0      0.0  0.01  5.799991e+18        16.0\n",
              "67     15.0     1.0    16.0      0.1  0.05  5.842078e+18        64.0\n",
              "16     15.0     1.0    64.0      0.1  0.01  5.859087e+18        16.0\n",
              "10     15.0     1.0    32.0      0.0  0.01  5.896109e+18        16.0\n",
              "86     15.0     2.0    16.0      0.0  0.01  5.918832e+18        64.0\n",
              "8      15.0     1.0    16.0      0.1  0.01  5.930424e+18        16.0\n",
              "18     15.0     1.0   128.0      0.0  0.01  5.979974e+18        16.0\n",
              "54     15.0     3.0    64.0      0.0  0.01  5.996624e+18        16.0\n",
              "68     15.0     1.0    16.0      0.1  0.01  6.008526e+18        64.0\n",
              "1      15.0     1.0     8.0      0.0  0.05  6.085882e+18        16.0\n",
              "70     15.0     1.0    32.0      0.0  0.01  6.118658e+18        64.0\n",
              "76     15.0     1.0    64.0      0.1  0.01  6.172236e+18        64.0\n",
              "83     15.0     2.0     8.0      0.1  0.05  6.183994e+18        64.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('GRU_results.csv').sort_values('mse').head(20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
